{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f6971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking all text fields against database schema limits...\n",
      "================================================================================\n",
      "\n",
      "üìä Found 7 field length violations:\n",
      "\n",
      "üî¥ Listing 2: amenity_code\n",
      "   Actual: 300 chars | Max: 255 chars | Excess: 45\n",
      "\n",
      "üî¥ Listing 4: amenity_code\n",
      "   Actual: 300 chars | Max: 255 chars | Excess: 45\n",
      "\n",
      "üî¥ Listing 23: amenity_code\n",
      "   Actual: 300 chars | Max: 255 chars | Excess: 45\n",
      "\n",
      "üî¥ Listing 78: amenity_code\n",
      "   Actual: 300 chars | Max: 255 chars | Excess: 45\n",
      "\n",
      "üî¥ Listing 93: amenity_code\n",
      "   Actual: 296 chars | Max: 255 chars | Excess: 41\n",
      "\n",
      "üî¥ Listing 93: amenity_code\n",
      "   Actual: 275 chars | Max: 255 chars | Excess: 20\n",
      "\n",
      "üî¥ Listing 99: amenity_code\n",
      "   Actual: 285 chars | Max: 255 chars | Excess: 30\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí° Solution: All violations need truncation in etl_airbnb_to_postgres.py\n"
     ]
    }
   ],
   "source": [
    "# Check all field lengths against database limits\n",
    "# exec(open('check_all_field_lengths.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5933d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n",
      "  Host: localhost\n",
      "  Database: airbnb_db\n",
      "  User: postgres\n",
      "  Port: 5432\n"
     ]
    }
   ],
   "source": [
    "DB_CONFIG = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),\n",
    "    'database': os.getenv('DB_NAME', 'airbnb_db'),\n",
    "    'user': os.getenv('DB_USER', 'postgres'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'port': int(os.getenv('DB_PORT', '5432'))\n",
    "}\n",
    "\n",
    "# File paths\n",
    "JSON_FILE = 'Resources/airbnb_beltline_calgary_listings_100.json'\n",
    "SCHEMA_FILE = 'database_normalized_schema.sql'\n",
    "\n",
    "print(\"‚úì Configuration loaded\")\n",
    "print(f\"  Host: {DB_CONFIG['host']}\")\n",
    "print(f\"  Database: {DB_CONFIG['database']}\")\n",
    "print(f\"  User: {DB_CONFIG['user']}\")\n",
    "print(f\"  Port: {DB_CONFIG['port']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276254af",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Database\n",
    "\n",
    "This creates the `airbnb_db` database if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4098b4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Checking if database 'airbnb_db' exists...\n",
      "‚ÑπÔ∏è  Database 'airbnb_db' already exists\n",
      "\n",
      "‚úÖ Step 4 Complete: Database ready\n",
      "\n",
      "‚ÑπÔ∏è  Database 'airbnb_db' already exists\n",
      "\n",
      "‚úÖ Step 4 Complete: Database ready\n"
     ]
    }
   ],
   "source": [
    "def create_database():\n",
    "    \"\"\"\n",
    "    Create the airbnb_db database if it doesn't exist.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to default postgres database\n",
    "        conn = psycopg2.connect(\n",
    "            host=DB_CONFIG['host'],\n",
    "            database='postgres',  # Connect to default DB first\n",
    "            user=DB_CONFIG['user'],\n",
    "            password=DB_CONFIG['password'],\n",
    "            port=DB_CONFIG['port']\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(f\"üîÑ Checking if database '{DB_CONFIG['database']}' exists...\")\n",
    "        \n",
    "        # Check if database exists\n",
    "        cursor.execute(\n",
    "            \"SELECT 1 FROM pg_database WHERE datname = %s\",\n",
    "            (DB_CONFIG['database'],)\n",
    "        )\n",
    "        \n",
    "        if cursor.fetchone():\n",
    "            print(f\"‚ÑπÔ∏è  Database '{DB_CONFIG['database']}' already exists\")\n",
    "        else:\n",
    "            # Create database\n",
    "            cursor.execute(\n",
    "                sql.SQL(\"CREATE DATABASE {}\").format(\n",
    "                    sql.Identifier(DB_CONFIG['database'])\n",
    "                )\n",
    "            )\n",
    "            print(f\"‚úÖ Database '{DB_CONFIG['database']}' created successfully\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"‚ùå Database error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Execute database creation\n",
    "if create_database():\n",
    "    print(\"\\n‚úÖ Step 4 Complete: Database ready\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Step 4 Failed: Check your PostgreSQL credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f66680",
   "metadata": {},
   "source": [
    "---\n",
    "##  Create Database Schema (15 Tables)\n",
    "\n",
    "This executes the SQL script to create all normalized tables with proper relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcfa2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating database schema from 'database_schema.sql'...\n",
      "\n",
      "‚úÖ Schema created successfully\n",
      "\n",
      "üìä Tables created (13 total):\n",
      "    1. amenities\n",
      "    2. amenity_groups\n",
      "    3. hosts\n",
      "    4. listing_amenities\n",
      "    5. listing_arrangement_details\n",
      "    6. listing_cancellation_policies\n",
      "    7. listing_category_ratings\n",
      "    8. listing_description_sections\n",
      "    9. listing_highlights\n",
      "   10. listing_house_rules\n",
      "   11. listing_location_details\n",
      "   12. listing_reviews\n",
      "   13. listings\n",
      "\n",
      "‚úÖ Step 5 Complete: Database structure ready\n",
      "\n",
      "‚úÖ Schema created successfully\n",
      "\n",
      "üìä Tables created (13 total):\n",
      "    1. amenities\n",
      "    2. amenity_groups\n",
      "    3. hosts\n",
      "    4. listing_amenities\n",
      "    5. listing_arrangement_details\n",
      "    6. listing_cancellation_policies\n",
      "    7. listing_category_ratings\n",
      "    8. listing_description_sections\n",
      "    9. listing_highlights\n",
      "   10. listing_house_rules\n",
      "   11. listing_location_details\n",
      "   12. listing_reviews\n",
      "   13. listings\n",
      "\n",
      "‚úÖ Step 5 Complete: Database structure ready\n"
     ]
    }
   ],
   "source": [
    "def create_schema():\n",
    "    \"\"\"\n",
    "    Execute SQL schema file to create database tables.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if schema file exists\n",
    "        schema_path = Path(SCHEMA_FILE)\n",
    "        if not schema_path.exists():\n",
    "            print(f\"‚ùå Schema file not found: {SCHEMA_FILE}\")\n",
    "            return False\n",
    "        \n",
    "        # Connect to airbnb_db\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(f\"üîÑ Creating database schema from '{SCHEMA_FILE}'...\")\n",
    "        \n",
    "        # Read and execute schema file\n",
    "        with open(schema_path, 'r', encoding='utf-8') as f:\n",
    "            schema_sql = f.read()\n",
    "        \n",
    "        cursor.execute(schema_sql)\n",
    "        conn.commit()\n",
    "        \n",
    "        # Verify tables created\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'public'\n",
    "            ORDER BY table_name\n",
    "        \"\"\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Schema created successfully\")\n",
    "        print(f\"\\nüìä Tables created ({len(tables)} total):\")\n",
    "        for i, (table_name,) in enumerate(tables, 1):\n",
    "            print(f\"   {i:2d}. {table_name}\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"‚ùå Database error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Execute schema creation\n",
    "if create_schema():\n",
    "    print(\"\\n‚úÖ Step 5 Complete: Database structure ready\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Step 5 Failed: Could not create schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ea155",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Preview JSON Data\n",
    "\n",
    "Let's load the JSON file and preview its structure before inserting into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec04041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading data from 'Resources/airbnb_beltline_calgary_listings_100.json'...\n",
      "‚úÖ Loaded 100 listings\n",
      "\n",
      "üìã Preview of first listing:\n",
      "   Name: Condo in Calgary ¬∑ ‚òÖ5.0 ¬∑ 1 bedroom ¬∑ 2 beds ¬∑ 1 bath\n",
      "   Price: $181.5\n",
      "   Location: Calgary, Alberta, Canada\n",
      "   Guests: 4\n",
      "   Rating: 5\n",
      "   Reviews: 3\n",
      "   Amenities: 13 groups\n",
      "\n",
      "‚úÖ Step 6 Complete: JSON data loaded\n"
     ]
    }
   ],
   "source": [
    "def load_json_data(json_file: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load Airbnb listings from JSON file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    json_file : str\n",
    "        Path to JSON file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        List of listing dictionaries\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_path = Path(json_file)\n",
    "        if not json_path.exists():\n",
    "            print(f\"‚ùå JSON file not found: {json_file}\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"üîÑ Loading data from '{json_file}'...\")\n",
    "        \n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            listings = json.load(f)\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {len(listings)} listings\")\n",
    "        return listings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load data\n",
    "listings = load_json_data(JSON_FILE)\n",
    "\n",
    "# Preview first listing\n",
    "if listings:\n",
    "    print(\"\\nüìã Preview of first listing:\")\n",
    "    first_listing = listings[0]\n",
    "    print(f\"   Name: {first_listing.get('name', 'N/A')}\")\n",
    "    print(f\"   Price: ${first_listing.get('price', 'N/A')}\")\n",
    "    print(f\"   Location: {first_listing.get('location', 'N/A')}\")\n",
    "    print(f\"   Guests: {first_listing.get('guests', 'N/A')}\")\n",
    "    print(f\"   Rating: {first_listing.get('ratings', 'N/A')}\")\n",
    "    print(f\"   Reviews: {len(first_listing.get('reviews', []))}\")\n",
    "    print(f\"   Amenities: {len(first_listing.get('amenities', []))} groups\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Step 6 Complete: JSON data loaded\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Step 6 Failed: Could not load JSON data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85b121",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data Using ETL Script\n",
    "\n",
    "Now we'll use the existing ETL script to load all the data into the database with proper normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ab8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ETL module reloaded with latest fixes\n"
     ]
    }
   ],
   "source": [
    "# Reload the ETL module to get the latest fixes\n",
    "import importlib\n",
    "import etl_airbnb_normalized_postgres\n",
    "importlib.reload(etl_airbnb_normalized_postgres)\n",
    "from etl_airbnb_normalized_postgres import AirbnbETL\n",
    "\n",
    "print(\"‚úÖ ETL module reloaded with latest fixes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534fdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 20:40:59,192 - INFO - Successfully connected to database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting ETL process...\n",
      "   This will insert data into all 15 tables with proper relationships.\n",
      "   This may take a minute...\n",
      "\n",
      "   Processing listing 1/100...\n",
      "   Processing listing 10/100...\n",
      "   Processing listing 10/100...\n",
      "   Processing listing 20/100...\n",
      "   Processing listing 30/100...\n",
      "   Processing listing 20/100...\n",
      "   Processing listing 30/100...\n",
      "   Processing listing 40/100...\n",
      "   Processing listing 50/100...\n",
      "   Processing listing 40/100...\n",
      "   Processing listing 50/100...\n",
      "   Processing listing 60/100...\n",
      "   Processing listing 70/100...\n",
      "   Processing listing 60/100...\n",
      "   Processing listing 70/100...\n",
      "   Processing listing 80/100...\n",
      "   Processing listing 90/100...\n",
      "   Processing listing 80/100...\n",
      "   Processing listing 90/100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 20:41:01,025 - INFO - Database connection closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processing listing 100/100...\n",
      "\n",
      "‚úÖ ETL Complete!\n",
      "   ‚úì Successfully processed: 100 listings\n",
      "\n",
      "‚úÖ Step 7 Complete: All data loaded into database\n"
     ]
    }
   ],
   "source": [
    "# Import the ETL class from the existing script\n",
    "from etl_airbnb_normalized_postgres import AirbnbETL\n",
    "import logging\n",
    "\n",
    "# Create a string buffer to capture error logs\n",
    "import io\n",
    "error_log_stream = io.StringIO()\n",
    "error_handler = logging.StreamHandler(error_log_stream)\n",
    "error_handler.setLevel(logging.ERROR)\n",
    "error_handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\n",
    "logging.getLogger('__main__').addHandler(error_handler)\n",
    "\n",
    "print(\"üîÑ Starting ETL process...\")\n",
    "print(\"   This will insert data into all 15 tables with proper relationships.\")\n",
    "print(\"   This may take a minute...\\n\")\n",
    "\n",
    "try:\n",
    "    # Initialize ETL\n",
    "    etl = AirbnbETL(DB_CONFIG)\n",
    "    \n",
    "    # Connect to database\n",
    "    etl.connect()\n",
    "    \n",
    "    # Process each listing\n",
    "    success_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for idx, listing in enumerate(listings, 1):\n",
    "        if idx % 10 == 0 or idx == 1:\n",
    "            print(f\"   Processing listing {idx}/{len(listings)}...\")\n",
    "        \n",
    "        if etl.process_listing(listing):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            failed_count += 1\n",
    "    \n",
    "    # No need to commit here - each listing commits individually\n",
    "    print(f\"\\n‚úÖ ETL Complete!\")\n",
    "    print(f\"   ‚úì Successfully processed: {success_count} listings\")\n",
    "    if failed_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Failed: {failed_count} listings\")\n",
    "    \n",
    "    # Disconnect\n",
    "    etl.disconnect()\n",
    "    \n",
    "    print(\"\\n‚úÖ Step 7 Complete: All data loaded into database\")\n",
    "    \n",
    "    # Show first 5 unique error messages\n",
    "    error_logs = error_log_stream.getvalue()\n",
    "    if error_logs:\n",
    "        print(\"\\nüìã Sample Error Messages (first 5 unique errors):\")\n",
    "        print(\"=\" * 80)\n",
    "        unique_errors = list(dict.fromkeys(error_logs.strip().split('\\n')))[:5]\n",
    "        for err in unique_errors:\n",
    "            print(f\"  ‚Ä¢ {err}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ETL Error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Check that PostgreSQL is running\")\n",
    "    print(\"  2. Verify your database password in Step 3\")\n",
    "    print(\"  3. Ensure database_normalized_schema.sql exists in the project folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb22ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Successfully inserted listings (100 total):\n",
      "================================================================================\n",
      "  1. 1426378005713860735: Condo in Calgary ¬∑ ‚òÖ5.0 ¬∑ 1 bedroom ¬∑ 2 beds ¬∑ 1 bath...\n",
      "  2. 779862525321826168: Rental unit in Calgary ¬∑ ‚òÖ4.85 ¬∑ 2 bedrooms ¬∑ 3 beds ¬∑ 1 bat...\n",
      "  3. 1375556219860316591: Rental unit in Calgary ¬∑ ‚òÖ4.95 ¬∑ 2 bedrooms ¬∑ 2 beds ¬∑ 1 bat...\n",
      "  4. 1404688484861443653: Condo in Calgary ¬∑ ‚òÖ4.94 ¬∑ 2 bedrooms ¬∑ 1 bed ¬∑ 1 bath...\n",
      "  5. 21869477: Rental unit in Calgary ¬∑ ‚òÖ4.93 ¬∑ 1 bedroom ¬∑ 1 bed ¬∑ 1 bath...\n",
      "  6. 1334815708091669351: Rental unit in Calgary ¬∑ ‚òÖ4.73 ¬∑ 2 bedrooms ¬∑ 2 beds ¬∑ 1 bat...\n",
      "  7. 1268959458721206253: Rental unit in Calgary ¬∑ ‚òÖ4.81 ¬∑ 1 bedroom ¬∑ 2 beds ¬∑ 1 bath...\n",
      "  8. 1429387547766358716: Rental unit in Calgary ¬∑ ‚òÖ4.74 ¬∑ 2 bedrooms ¬∑ 2 beds ¬∑ 2 bat...\n",
      "  9. 877853278978311875: Rental unit in Calgary ¬∑ ‚òÖ4.82 ¬∑ 2 bedrooms ¬∑ 1 bed ¬∑ 1 bath...\n",
      "  10. 1249574984122191715: Rental unit in Calgary ¬∑ ‚òÖ4.87 ¬∑ 2 bedrooms ¬∑ 2 beds ¬∑ 2 bat...\n",
      "  ... and 90 more\n",
      "\n",
      "‚ùå Failed listing indices: []...\n",
      "\n",
      "üí° Total failed: 0\n"
     ]
    }
   ],
   "source": [
    "cur = psycopg2.connect(**DB_CONFIG).cursor()\n",
    "cur.execute(\"SELECT listing_id, property_id, name FROM listings ORDER BY listing_id\")\n",
    "successful_listings = cur.fetchall()\n",
    "cur.close()\n",
    "\n",
    "print(f\"\\nüìä Successfully inserted listings ({len(successful_listings)} total):\")\n",
    "print(\"=\"  * 80)\n",
    "for lid, prop_id, name in successful_listings[:10]:  # Show first 10\n",
    "    print(f\"  {lid}. {prop_id}: {name[:60]}...\")\n",
    "if len(successful_listings) > 10:\n",
    "    print(f\"  ... and {len(successful_listings) - 10} more\")\n",
    "\n",
    "# Check which listing indices from our JSON were successful\n",
    "successful_prop_ids = {prop_id for _, prop_id, _ in successful_listings}\n",
    "failed_indices = []\n",
    "for idx, listing in enumerate(listings, 1):\n",
    "    if listing.get('property_id') not in successful_prop_ids:\n",
    "        failed_indices.append(idx)\n",
    "\n",
    "print(f\"\\n‚ùå Failed listing indices: {failed_indices[:20]}...\")  # Show first 20\n",
    "print(f\"\\nüí° Total failed: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77906e67",
   "metadata": {},
   "source": [
    "---\n",
    "## Validate the Data\n",
    "\n",
    "Let's verify that data was loaded correctly by checking row counts in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b01c321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Database Statistics:\n",
      "\n",
      "Table Name                           Row Count\n",
      "-----------------------------------------------\n",
      "amenities                                  383\n",
      "amenity_groups                              14\n",
      "hosts                                       65\n",
      "listing_amenities                        4,834\n",
      "listing_arrangement_details                158\n",
      "listing_cancellation_policies              141\n",
      "listing_category_ratings                   558\n",
      "listing_description_sections               412\n",
      "listing_highlights                         291\n",
      "listing_house_rules                        300\n",
      "listing_location_details                    80\n",
      "listing_reviews                          1,932\n",
      "listings                                   100\n",
      "-----------------------------------------------\n",
      "TOTAL                                    9,268\n",
      "\n",
      "‚úÖ Step 8 Complete: Data validation successful\n"
     ]
    }
   ],
   "source": [
    "def validate_data():\n",
    "    \"\"\"\n",
    "    Check row counts in all tables to validate data loading.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with table names and row counts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get all table names\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'public'\n",
    "            ORDER BY table_name\n",
    "        \"\"\")\n",
    "        tables = [row[0] for row in cursor.fetchall()]\n",
    "        \n",
    "        print(\"üìä Database Statistics:\\n\")\n",
    "        print(f\"{'Table Name':<35} {'Row Count':>10}\")\n",
    "        print(\"-\" * 47)\n",
    "        \n",
    "        table_counts = {}\n",
    "        total_rows = 0\n",
    "        \n",
    "        for table in tables:\n",
    "            cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            table_counts[table] = count\n",
    "            total_rows += count\n",
    "            print(f\"{table:<35} {count:>10,}\")\n",
    "        \n",
    "        print(\"-\" * 47)\n",
    "        print(f\"{'TOTAL':<35} {total_rows:>10,}\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return table_counts\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Validation error: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Run validation\n",
    "table_counts = validate_data()\n",
    "\n",
    "if table_counts:\n",
    "    print(\"\\n‚úÖ Step 8 Complete: Data validation successful\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Step 8 Failed: Could not validate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118eb24",
   "metadata": {},
   "source": [
    "---\n",
    "## Some Sample Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6764d",
   "metadata": {},
   "source": [
    "### Query 1: Top 10 Highest-Rated Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37613348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä Top 10 Highest-Rated Listings\n",
      "================================================================================\n",
      "\n",
      "name            | price           | rating          | guests          | number_of_revie\n",
      "---------------------------------------------------------------------------------------\n",
      "Condo in Calgar | 160.00          | 5.00            | 4               | 55             \n",
      "Rental unit in  | 153.97          | 5.00            | 2               | 39             \n",
      "Rental unit in  | 124.96          | 5.00            | 2               | 29             \n",
      "Condo in Calgar | 183.37          | 5.00            | 4               | 20             \n",
      "Rental unit in  | 145.50          | 5.00            | 2               | 19             \n",
      "Condo in Calgar | 154.90          | 5.00            | 4               | 15             \n",
      "Condo in Calgar | 292.33          | 5.00            | 4               | 15             \n",
      "Condo in Calgar | 265.33          | 5.00            | 4               | 10             \n",
      "Rental unit in  | 179.00          | 5.00            | 2               | 7              \n",
      "Condo in Calgar | 250.49          | 5.00            | 4               | 5              \n"
     ]
    }
   ],
   "source": [
    "def run_query(query_name: str, query: str):\n",
    "    \"\"\"\n",
    "    Execute a SQL query and display results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query_name : str\n",
    "        Name of the query for display\n",
    "    query : str\n",
    "        SQL query to execute\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìä {query_name}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        \n",
    "        if results:\n",
    "            # Get column names\n",
    "            colnames = [desc[0] for desc in cursor.description]\n",
    "            \n",
    "            # Print header\n",
    "            header = \" | \".join(f\"{col[:15]:<15}\" for col in colnames)\n",
    "            print(header)\n",
    "            print(\"-\" * len(header))\n",
    "            \n",
    "            # Print rows (limit to 10)\n",
    "            for row in results[:10]:\n",
    "                row_str = \" | \".join(f\"{str(val)[:15]:<15}\" for val in row)\n",
    "                print(row_str)\n",
    "            \n",
    "            if len(results) > 10:\n",
    "                print(f\"\\n... ({len(results) - 10} more rows)\")\n",
    "        else:\n",
    "            print(\"No results found.\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Query error: {e}\")\n",
    "\n",
    "# Query 1: Top-rated listings\n",
    "query1 = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    price,\n",
    "    rating,\n",
    "    guests,\n",
    "    number_of_reviews\n",
    "FROM listings\n",
    "WHERE rating IS NOT NULL\n",
    "ORDER BY rating DESC, number_of_reviews DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "run_query(\"Top 10 Highest-Rated Listings\", query1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086a68b",
   "metadata": {},
   "source": [
    "### Query 2: Average Price by Number of Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f80c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä Average Price by Number of Bedrooms\n",
      "================================================================================\n",
      "\n",
      "bedrooms        | listing_count   | avg_price       | min_price       | max_price      \n",
      "---------------------------------------------------------------------------------------\n",
      "1               | 36              | 171.63          | 115.67          | 292.33         \n",
      "2               | 41              | 199.65          | 140.94          | 345.00         \n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    bedrooms,\n",
    "    COUNT(*) as listing_count,\n",
    "    ROUND(AVG(price), 2) as avg_price,\n",
    "    ROUND(MIN(price), 2) as min_price,\n",
    "    ROUND(MAX(price), 2) as max_price\n",
    "FROM listings\n",
    "WHERE bedrooms IS NOT NULL AND price IS NOT NULL\n",
    "GROUP BY bedrooms\n",
    "ORDER BY bedrooms;\n",
    "\"\"\"\n",
    "\n",
    "run_query(\"Average Price by Number of Bedrooms\", query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9e353",
   "metadata": {},
   "source": [
    "### Query 3: Most Common Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63758d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä Most Common Amenities (Top 15)\n",
      "================================================================================\n",
      "\n",
      "group_name      | amenity_name    | listing_count   | percentage     \n",
      "---------------------------------------------------------------------\n",
      "Kitchen and din | Kitchen         | 99              | 99.0           \n",
      "Home safety     | Smoke alarm     | 97              | 97.0           \n",
      "Bathroom        | Hair dryer      | 93              | 93.0           \n",
      "Bedroom and lau | Iron            | 92              | 92.0           \n",
      "Kitchen and din | Cooking basics  | 91              | 91.0           \n",
      "Internet and of | Wifi            | 90              | 90.0           \n",
      "Bathroom        | Hot water       | 90              | 90.0           \n",
      "Kitchen and din | Microwave       | 89              | 89.0           \n",
      "Home safety     | Carbon monoxide | 89              | 89.0           \n",
      "Bedroom and lau | Hangers         | 89              | 89.0           \n",
      "\n",
      "... (309 more rows)\n"
     ]
    }
   ],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    ag.group_name,\n",
    "    a.amenity_name,\n",
    "    COUNT(DISTINCT la.listing_id) as listing_count,\n",
    "    ROUND(COUNT(DISTINCT la.listing_id) * 100.0 / \n",
    "          (SELECT COUNT(*) FROM listings), 1) as percentage\n",
    "FROM amenity_groups ag\n",
    "JOIN amenities a ON ag.group_id = a.group_id\n",
    "JOIN listing_amenities la ON a.amenity_id = la.amenity_id\n",
    "GROUP BY ag.group_name, a.amenity_name\n",
    "ORDER BY listing_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "run_query(\"Most Common Amenities (Top 15)\", query3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f799aba",
   "metadata": {},
   "source": [
    "### Query 4: Superhost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87ed479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä Superhost vs Regular Host Comparison\n",
      "================================================================================\n",
      "\n",
      "is_superhost    | host_count      | total_listings  | avg_rating      | avg_price       | avg_response_ra\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "True            | 43              | 71              | 4.89            | 186.36          | 99.7           \n",
      "False           | 22              | 29              | 4.11            | 185.90          | 98.9           \n",
      "is_superhost    | host_count      | total_listings  | avg_rating      | avg_price       | avg_response_ra\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "True            | 43              | 71              | 4.89            | 186.36          | 99.7           \n",
      "False           | 22              | 29              | 4.11            | 185.90          | 98.9           \n"
     ]
    }
   ],
   "source": [
    "query4 = \"\"\"\n",
    "SELECT \n",
    "    h.is_superhost,\n",
    "    COUNT(DISTINCT h.host_id) as host_count,\n",
    "    COUNT(l.listing_id) as total_listings,\n",
    "    ROUND(AVG(l.rating), 2) as avg_rating,\n",
    "    ROUND(AVG(l.price), 2) as avg_price,\n",
    "    ROUND(AVG(h.response_rate), 1) as avg_response_rate\n",
    "FROM hosts h\n",
    "LEFT JOIN listings l ON h.host_id = l.host_id\n",
    "GROUP BY h.is_superhost\n",
    "ORDER BY h.is_superhost DESC;\n",
    "\"\"\"\n",
    "\n",
    "run_query(\"Superhost vs Regular Host Comparison\", query4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c2889",
   "metadata": {},
   "source": [
    "### Query 5: Category Ratings Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35b37c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä Category Ratings Analysis\n",
      "================================================================================\n",
      "\n",
      "category_name   | avg_rating      | min_rating      | max_rating      | listing_count  \n",
      "---------------------------------------------------------------------------------------\n",
      "Communication   | 4.91            | 4.00            | 5.00            | 93             \n",
      "Location        | 4.90            | 4.00            | 5.00            | 93             \n",
      "Accuracy        | 4.89            | 4.40            | 5.00            | 93             \n",
      "Cleanliness     | 4.84            | 4.00            | 5.00            | 93             \n",
      "Check-in        | 4.83            | 4.30            | 5.00            | 93             \n",
      "Value           | 4.80            | 4.20            | 5.00            | 93             \n",
      "\n",
      "‚úÖ Step 9 Complete: Sample queries executed successfully\n",
      "category_name   | avg_rating      | min_rating      | max_rating      | listing_count  \n",
      "---------------------------------------------------------------------------------------\n",
      "Communication   | 4.91            | 4.00            | 5.00            | 93             \n",
      "Location        | 4.90            | 4.00            | 5.00            | 93             \n",
      "Accuracy        | 4.89            | 4.40            | 5.00            | 93             \n",
      "Cleanliness     | 4.84            | 4.00            | 5.00            | 93             \n",
      "Check-in        | 4.83            | 4.30            | 5.00            | 93             \n",
      "Value           | 4.80            | 4.20            | 5.00            | 93             \n",
      "\n",
      "‚úÖ Step 9 Complete: Sample queries executed successfully\n"
     ]
    }
   ],
   "source": [
    "query5 = \"\"\"\n",
    "SELECT \n",
    "    category_name,\n",
    "    ROUND(AVG(rating_value), 2) as avg_rating,\n",
    "    ROUND(MIN(rating_value), 2) as min_rating,\n",
    "    ROUND(MAX(rating_value), 2) as max_rating,\n",
    "    COUNT(DISTINCT listing_id) as listing_count\n",
    "FROM listing_category_ratings\n",
    "GROUP BY category_name\n",
    "ORDER BY avg_rating DESC;\n",
    "\"\"\"\n",
    "\n",
    "run_query(\"Category Ratings Analysis\", query5)\n",
    "\n",
    "print(\"\\n‚úÖ Step 9 Complete: Sample queries executed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb-price-optimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
